# java客户端

引入依赖,最后使用和服务器版本一致的客户端版本。

```xml
<dependency>
    <groupId>org.apache.kafka</groupId>
    <artifactId>kafka-clients</artifactId>
    <version>2.5.0</version>
</dependency>
```

## 生产者

示例代码在`org.apache.kafka.clients.producer.KafkaProducer` 的类注释中，参考该注释，编写我们的生产者。

```java
public class DemoProducer {

    public static void main(String[] args) {

        String topic = "testTopic01";

        Properties properties = new Properties();
        properties.put("bootstrap.servers", "192.168.80.130:9092");
        properties.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
        properties.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");
        properties.put("acks", "all");

        Producer<String, String> producer = new KafkaProducer<>(properties);

        for (int i = 0; i < 10; i++) {
            ProducerRecord<String, String> record = new ProducerRecord<>(topic, "v" + i, "v" + i);
            producer.send(record);
        }

        producer.close();
    }
}
```

主要通过一个`properties`进行配置，配置服务的端口和序列化器。

实例化生产者 ` Producer` ,发送` ProducerRecord` 也就是一条消息。



## 消费者

示例代码同样在`org.apache.kafka.clients.consumer.KafkaConsumer` 中，这里一定要用main方法，而不是junit。

```java
public class DemoConsumer {

    public static void main(String[] args) {

        String topic = "testTopic01";

        Properties properties = new Properties();
        properties.put("bootstrap.servers", "192.168.80.130:9092");
        properties.put("group.id", "java01");
        properties.put("enable.auto.commit", "true");
        properties.put("auto.commit.interval.ms", "1000");
        properties.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
        properties.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");

        KafkaConsumer<String, String> kafkaConsumer = new KafkaConsumer<>(properties);
        kafkaConsumer.subscribe(Collections.singletonList(topic));

        while (true) {
            ConsumerRecords<String, String> records = kafkaConsumer.poll(Duration.ofSeconds(10));
            System.out.println("count:" + records.count());
            for (ConsumerRecord<String, String> record : records) {
                System.out.print("offset:" + record.offset());
                System.out.print(",key:" + record.key());
                System.out.println(",value:" + record.value());
            }
        }
    }
}
```

同样的使用properties设置属性，其中`group.id `为消费者组的id,并且开启消息自动提交，并设置自动提交的时间。注意这里的是反序化器。

创建消费者实例`KafkaConsumer`，订阅一个topic集合，可以看出是可以订阅多个topic的。

在while(true)中去获取消息，指定一个时间窗口,如果有消息，则立刻返回，如果没有消息，将等待这个时间窗口过后，返回一个空集合，进行消费。

## 配置优化

可以使用 `org.apache.kafka.clients.producer.ProducerConfig` 和 `org.apache.kafka.clients.consumer.ConsumerConfig` 代替原来的字符串，防止写错。

改写后

```java
Properties properties = new Properties();
properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "192.168.80.130:9092");
properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
properties.put(ProducerConfig.ACKS_CONFIG, "all");
```

```java
Properties properties = new Properties();
properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, "192.168.80.130:9092");
properties.put(ConsumerConfig.GROUP_ID_CONFIG, "java01");
properties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, "true");
properties.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, "1000");
properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
```

## 发送方式

### 只发送

直接发送的方式，可能存在问题，不知道发送成功没。

```java
producer.send(record);
```

### 同步发送

```java
Future<RecordMetadata> metadataFuture = producer.send(record);
RecordMetadata recordMetadata = metadataFuture.get();
System.out.println("partition:" + recordMetadata.partition() + ",offset:" + recordMetadata.offset());
        
```

send方法会返回一个Future对象，当调用get时，会同步等待发送结果，可以看到发送到了什么分区，哪个位置。

### 异步发送

```java
producer.send(record, new Callback() {
    @Override
    public void onCompletion(RecordMetadata metadata, Exception exception) {
        System.out.println("partition:" + metadata.partition() + ",offset:" + metadata.offset());
        System.out.println("ex:" + exception);
    }
});
```

异步发送，则发送时指定一个回调函数，不管发送完成还是失败都会调用该回调函数，根据参数判断是否成功。

可以改为 lambda形式。

```java
producer.send(record, (metadata, exception) -> {
    System.out.println("partition:" + metadata.partition() + ",offset:" + metadata.offset());
    System.out.println("ex:" + exception);
});
```

## 序列化器

实现`org.apache.kafka.common.serialization.Serializer` 接口，自定义序列化器，不过一般提供的序列化器已经足够使用。




# java客户端

引入依赖,最后使用和服务器版本一致的客户端版本。

```xml
<dependency>
    <groupId>org.apache.kafka</groupId>
    <artifactId>kafka-clients</artifactId>
    <version>2.5.0</version>
</dependency>
```

## 生产者

示例代码在`org.apache.kafka.clients.producer.KafkaProducer` 的类注释中，参考该注释，编写我们的生产者。

```java
public class DemoProducer {

    public static void main(String[] args) {

        String topic = "testTopic01";

        Properties properties = new Properties();
        properties.put("bootstrap.servers", "192.168.80.130:9092");
        properties.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
        properties.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");
        properties.put("acks", "all");

        Producer<String, String> producer = new KafkaProducer<>(properties);

        for (int i = 0; i < 10; i++) {
            ProducerRecord<String, String> record = new ProducerRecord<>(topic, "v" + i, "v" + i);
            producer.send(record);
        }

        producer.close();
    }
}
```

主要通过一个`properties`进行配置，配置服务的端口和序列化器。

实例化生产者 ` Producer` ,发送` ProducerRecord` 也就是一条消息。



## 消费者

示例代码同样在`org.apache.kafka.clients.consumer.KafkaConsumer` 中，这里一定要用main方法，而不是junit。

```java
public class DemoConsumer {

    public static void main(String[] args) {

        String topic = "testTopic01";

        Properties properties = new Properties();
        properties.put("bootstrap.servers", "192.168.80.130:9092");
        properties.put("group.id", "java01");
        properties.put("enable.auto.commit", "true");
        properties.put("auto.commit.interval.ms", "1000");
        properties.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
        properties.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");

        KafkaConsumer<String, String> kafkaConsumer = new KafkaConsumer<>(properties);
        kafkaConsumer.subscribe(Collections.singletonList(topic));

        while (true) {
            ConsumerRecords<String, String> records = kafkaConsumer.poll(Duration.ofSeconds(10));
            System.out.println("count:" + records.count());
            for (ConsumerRecord<String, String> record : records) {
                System.out.print("offset:" + record.offset());
                System.out.print(",key:" + record.key());
                System.out.println(",value:" + record.value());
            }
        }
    }
}
```

同样的使用properties设置属性，其中`group.id `为消费者组的id,并且开启消息自动提交，并设置自动提交的时间。注意这里的是反序化器。

创建消费者实例`KafkaConsumer`，订阅一个topic集合，可以看出是可以订阅多个topic的。

在while(true)中去获取消息，指定一个时间窗口,如果有消息，则立刻返回，如果没有消息，将等待这个时间窗口过后，返回一个空集合，进行消费。

## 配置优化

可以使用 `org.apache.kafka.clients.producer.ProducerConfig` 和 `org.apache.kafka.clients.consumer.ConsumerConfig` 代替原来的字符串，防止写错。

改写后

```java
Properties properties = new Properties();
properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "192.168.80.130:9092");
properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
properties.put(ProducerConfig.ACKS_CONFIG, "all");
```

```java
Properties properties = new Properties();
properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, "192.168.80.130:9092");
properties.put(ConsumerConfig.GROUP_ID_CONFIG, "java01");
properties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, "true");
properties.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, "1000");
properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
```

## 发送方式

### 只发送

直接发送的方式，可能存在问题，不知道发送成功没。

```java
producer.send(record);
```

### 同步发送

```java
Future<RecordMetadata> metadataFuture = producer.send(record);
RecordMetadata recordMetadata = metadataFuture.get();
System.out.println("partition:" + recordMetadata.partition() + ",offset:" + recordMetadata.offset());
```

send方法会返回一个Future对象，当调用get时，会同步等待发送结果，可以看到发送到了什么分区，哪个位置。

### 异步发送

```java
producer.send(record, new Callback() {
    @Override
    public void onCompletion(RecordMetadata metadata, Exception exception) {
        System.out.println("partition:" + metadata.partition() + ",offset:" + metadata.offset());
        System.out.println("ex:" + exception);
    }
});
```

异步发送，则发送时指定一个回调函数，不管发送完成还是失败都会调用该回调函数，根据参数判断是否成功。

可以改为 lambda形式。

```java
producer.send(record, (metadata, exception) -> {
    System.out.println("partition:" + metadata.partition() + ",offset:" + metadata.offset());
    System.out.println("ex:" + exception);
});
```

## 序列化器

实现`org.apache.kafka.common.serialization.Serializer` 接口，自定义序列化器，不过一般提供的序列化器已经足够使用。



## 分区器

发送的时候根据一定的规则，发送到指定topic的下的分区partition下。

分区器实现`org.apache.kafka.clients.producer.Partitioner` 接口

默认的分区器为 `org.apache.kafka.clients.producer.internals.DefaultPartitioner`，其实现为根据key的hash推算。

# 配置

大部分配置都有默认的合理值，也可以根据特殊需求进行定制。

## 生产者

### acks

该配置是字符串类型，决定确认消息是否发送成功

配置为 0 表示不等待服务器确认，并且 retries 配置不会生效。

配置为 1 表示等待主节点保存，不等待副本节点保存。

配置为 -1 或 all 表示等待所有节点保存。

配置不对会报错，默认为 1 。

```
Invalid value xx for configuration acks: String must be one of: all, -1, 0, 1
```

### retries

指定重试次数，默认为 2147483647 也就是 int 的最大值 ，可以在指定时间窗口内重试，可以配置 `retries.backoff.ms`配置重试时间,默认为 100ms。

## 消费者

### group.id

指定一个消费者组，kafka允许任意消费者组，来消费这条消息，同一个消费者组下的多个消费者不会重复消费。

### topic

一个消费者可以一次订阅多个topic

```java
kafkaConsumer.subscribe(Arrays.asList("testTopic01","testTopic02"));
```

还可以指定正则表达式

```java
kafkaConsumer.subscribe(Pattern.compile("testTopic*"));
```

### partition

指定消费的分区，发送消息的时候默认根据key的不同发送到不同的分区，同一个消费者组下的多个消费者消费不同分区下的消息。这里可以指定要消费的分区。

订阅topic,partition,pattern应该是互斥的，重合则报错。

通过一个数组指定。

```java
kafkaConsumer.assign(Arrays.asList(new TopicPartition("testTopic01",0)));
```

### offset

offset是`kafka`消息的确认机制。每一条消息的产生，在消息队列中,一个topic主题下的partition分区下的所有消息，按照offset偏移量排序，消费者消费的时候会记录当前的offset，消费时按照offset顺序消费，下次消费从该位置继续。

默认情况为自动提交offset，通过配置`enable.auto.commit`，和`auto.commit.interval.ms` 自动提交的周期时间（默认1000）来提交offset，会在一次poll方法调用后，周期性提交，此情况可能导致消息丢失和重复消费。

消息丢失：消费者接收到消息，还没开始处理消息，宕机了，此时offset已提交，重启后不会再接收到刚才的消息。

重复消费：消费者接收到消息，处理完成，但是offset还没提交，下次消费还是从上次的位置开始继续消费该消息。

#### 手动提交

为防止以上情况，设置为手动提交offset，如果设置了手动提交，要记得提交，不然重启的时候，会反复消费。

```java
properties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false);
```

手动提交offset，提交可以分为同步和异步，提交会把这一次poll的最后一位提交上去。

```java
while (true) {
    ConsumerRecords<String, String> records = kafkaConsumer.poll(Duration.ofSeconds(10));
    for (ConsumerRecord<String, String> record : records) {
        System.out.print("offset:" + record.offset());
        System.out.print(",key:" + record.key());
        System.out.println(",value:" + record.value());
    }
     kafkaConsumer.commitSync();
     //kafkaConsumer.commitAsync();
}
```

提交后还可查看指定topic分区下已经提交到了多少位。

```java
OffsetAndMetadata offsetAndMetadata = kafkaConsumer.committed(new TopicPartition("testTopic02", 0));
long offset = offsetAndMetadata.offset();
```

#### seek

seek可以指定偏移量进行消费

```java
// 需要先poll一下分配分区
kafkaConsumer.poll(Duration.ofSeconds(1));
// 指定从该分区的指定偏移量进行消费
kafkaConsumer.seek(new TopicPartition("testTopic02",0),10);
while (true) {
    ConsumerRecords<String, String> records = kafkaConsumer.poll(Duration.ofSeconds(10));
    for (ConsumerRecord<String, String> record : records) {
        System.out.print("offset:" + record.offset());
        System.out.print(",key:" + record.key());
        System.out.println(",value:" + record.value());
    }
}
```

# AdminClient

kafka除了可以使用命令行进行操作kafka，还提供了 java api 去操作，如增加topic，增加分区等。

创建`org.apache.kafka.clients.admin.AdminClient` 对象，进行操作。

```java
Properties properties = new Properties();
properties.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG,"192.168.80.130:9092");

AdminClient adminClient = AdminClient.create(properties);

// 创建topic
NewTopic newTopic = new NewTopic("testTopic05",2,(short)1);
CreateTopicsResult createTopicsResult = adminClient.createTopics(Collections.singletonList(newTopic));
createTopicsResult.all().get();

// 查看topic
ListTopicsResult listTopicsResult = adminClient.listTopics();
Set<String> topicNames = listTopicsResult.names().get();
topicNames.forEach(System.out::println);

adminClient.close();
```

